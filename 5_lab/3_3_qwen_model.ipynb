{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь тестируется не Seq2Seq, а Decoder-Only модель, из-за чего таргет так-же включает в себя промпт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import uuid\n",
    "import os\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType # type: ignore\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset.from_parquet('./__output__/matched_train.parquet')\n",
    "test = Dataset.from_parquet('./__output__/matched_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['nmId', 'text', 'responder', 'type', 'product_name', 'product_category_2', 'product_category_1', 'product_color', 'product_description', 'product_brand', 'vector', 'toxicity', 'emotions', 'target_nmId', 'target_text', 'target_responder', 'target_type', 'target_product_name', 'target_product_category_2', 'target_product_category_1', 'target_product_color', 'target_product_description', 'target_product_brand', 'target_vector', 'target_toxicity', 'target_emotions', '__index_level_0__'],\n",
       "    num_rows: 15147\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['nmId', 'text', 'responder', 'type', 'product_name', 'product_category_2', 'product_category_1', 'product_color', 'product_description', 'product_brand', 'vector', 'toxicity', 'emotions', 'target_nmId', 'target_text', 'target_responder', 'target_type', 'target_product_name', 'target_product_category_2', 'target_product_category_1', 'target_product_color', 'target_product_description', 'target_product_brand', 'target_vector', 'target_toxicity', 'target_emotions', '__index_level_0__'],\n",
       "    num_rows: 1683\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'Qwen/Qwen2.5-0.5B',\n",
    "    device_map='cuda:0',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation='flash_attention_2'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'Qwen/Qwen2.5-0.5B',\n",
    "    useFast=True\n",
    ")\n",
    "\n",
    "coll = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494032768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_conf = LoraConfig(\n",
    "    TaskType.SEQ_2_SEQ_LM,\n",
    "    r=12,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    inference_mode=False\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "811008"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in peft_model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.tokenize(row['text'])) for row in train]) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.tokenize(row['target_text'])) for row in train]) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(e):\n",
    "    out = tokenizer(\n",
    "        f'''\n",
    "ответчик: {e['target_responder']}\n",
    "тип: {e['target_type']}\n",
    "название: {e['target_product_name']}\n",
    "категория 2: {e['target_product_category_2']}\n",
    "цвет: {e['target_product_color']}\n",
    "бренд: {e['target_product_brand']}\n",
    "описание: {e['target_product_description']}\n",
    "токсичность: {e['toxicity']}\n",
    "эиоциональность: {e['emotions']}\n",
    "текст: {e['text']}\n",
    "ответ:\n",
    "        ''',\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=1000,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    out['input_ids'] = out['input_ids'][0] # type: ignore\n",
    "    out['attention_mask'] = out['attention_mask'][0] # type: ignore\n",
    "\n",
    "    labels = tokenizer(\n",
    "         f'''\n",
    "ответчик: {e['target_responder']}\n",
    "тип: {e['target_type']}\n",
    "название: {e['target_product_name']}\n",
    "категория 2: {e['target_product_category_2']}\n",
    "цвет: {e['target_product_color']}\n",
    "бренд: {e['target_product_brand']}\n",
    "описание: {e['target_product_description']}\n",
    "токсичность: {e['toxicity']}\n",
    "эиоциональность: {e['emotions']}\n",
    "текст: {e['text']}\n",
    "ответ:\n",
    "{e['target_text']}\n",
    "        ''',\n",
    "        text_target=e['target_text'], \n",
    "        max_length=1500,         \n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    out['labels'] = labels['input_ids'][0] # type: ignore\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7226595330334c748109de1ca63b030b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d613c06d4de496799e4c1d02af120a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1683 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 15147\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.map(preprocess, remove_columns=train.column_names) # type: ignore\n",
    "test = test.map(preprocess, remove_columns=test.column_names) # type: ignore\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3fd3a3fb-f114-485d-8611-8ae6f233f1c2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = str(uuid.uuid4())\n",
    "\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'./models/{checkpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=f'./models/{checkpoint}/runs',\n",
    "    eval_strategy='epoch',\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=0.001,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='no',\n",
    "    remove_unused_columns=False,\n",
    "    bf16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model, # type: ignore\n",
    "    args=args,\n",
    "    data_collator=coll,\n",
    "    train_dataset=train, # type: ignore\n",
    "    eval_dataset=test, # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37870' max='37870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37870/37870 2:20:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.960500</td>\n",
       "      <td>1.955670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.136800</td>\n",
       "      <td>3.470997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.742300</td>\n",
       "      <td>3.605571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.563000</td>\n",
       "      <td>3.470597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.535900</td>\n",
       "      <td>3.412648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37870, training_loss=3.012409730180449, metrics={'train_runtime': 8430.678, 'train_samples_per_second': 8.983, 'train_steps_per_second': 4.492, 'total_flos': 1.630010112192e+17, 'train_loss': 3.012409730180449, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(f'./models/{checkpoint}/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "meteor = evaluate.load('evaluate-metric/meteor')\n",
    "rouge = evaluate.load('evaluate-metric/rouge')\n",
    "bleu = evaluate.load('evaluate-metric/bleu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за долгого инференса, реимпортирую модель, но теперь с flash_attention2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5855afa6854ff297774bac30d6ba2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batching examples:   0%|          | 0/1683 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/85 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  1%|          | 1/85 [00:17<25:11, 17.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  2%|▏         | 2/85 [00:34<23:37, 17.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  4%|▎         | 3/85 [00:50<22:55, 16.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  5%|▍         | 4/85 [01:06<22:17, 16.51s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|▌         | 5/85 [01:23<21:48, 16.36s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  7%|▋         | 6/85 [01:39<21:25, 16.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  8%|▊         | 7/85 [01:55<21:05, 16.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|▉         | 8/85 [02:11<20:46, 16.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█         | 9/85 [02:27<20:29, 16.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 12%|█▏        | 10/85 [02:43<20:10, 16.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 13%|█▎        | 11/85 [02:59<19:56, 16.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|█▍        | 12/85 [03:16<19:42, 16.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 15%|█▌        | 13/85 [03:32<19:27, 16.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 16%|█▋        | 14/85 [03:48<19:13, 16.24s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 18%|█▊        | 15/85 [04:04<18:55, 16.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 19%|█▉        | 16/85 [04:20<18:35, 16.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|██        | 17/85 [04:40<19:23, 17.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 21%|██        | 18/85 [04:59<19:49, 17.75s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 22%|██▏       | 19/85 [05:18<20:00, 18.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 24%|██▎       | 20/85 [05:37<20:03, 18.51s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 25%|██▍       | 21/85 [05:54<19:02, 17.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|██▌       | 22/85 [06:10<18:09, 17.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 27%|██▋       | 23/85 [06:26<17:28, 16.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 28%|██▊       | 24/85 [06:45<18:00, 17.71s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|██▉       | 25/85 [07:05<18:22, 18.37s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|███       | 26/85 [07:25<18:22, 18.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 32%|███▏      | 27/85 [07:44<18:15, 18.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 33%|███▎      | 28/85 [08:04<18:10, 19.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|███▍      | 29/85 [08:23<18:00, 19.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 35%|███▌      | 30/85 [08:42<17:38, 19.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 36%|███▋      | 31/85 [09:01<17:11, 19.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 38%|███▊      | 32/85 [09:19<16:30, 18.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 39%|███▉      | 33/85 [09:36<15:53, 18.34s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████      | 34/85 [09:54<15:24, 18.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 41%|████      | 35/85 [10:12<15:05, 18.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 42%|████▏     | 36/85 [10:30<14:44, 18.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 44%|████▎     | 37/85 [10:48<14:28, 18.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 45%|████▍     | 38/85 [11:06<13:58, 17.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|████▌     | 39/85 [11:23<13:31, 17.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 47%|████▋     | 40/85 [11:40<13:15, 17.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 48%|████▊     | 41/85 [11:59<13:02, 17.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|████▉     | 42/85 [12:16<12:40, 17.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|█████     | 43/85 [12:34<12:22, 17.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 52%|█████▏    | 44/85 [12:52<12:07, 17.73s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 53%|█████▎    | 45/85 [13:10<12:03, 18.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|█████▍    | 46/85 [13:29<11:47, 18.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 55%|█████▌    | 47/85 [13:45<11:13, 17.71s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 56%|█████▋    | 48/85 [14:03<10:50, 17.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 58%|█████▊    | 49/85 [14:21<10:44, 17.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 59%|█████▉    | 50/85 [14:39<10:26, 17.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|██████    | 51/85 [14:57<10:12, 18.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 61%|██████    | 52/85 [15:14<09:40, 17.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 62%|██████▏   | 53/85 [15:32<09:21, 17.55s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 64%|██████▎   | 54/85 [15:50<09:09, 17.72s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 65%|██████▍   | 55/85 [16:08<09:00, 18.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|██████▌   | 56/85 [16:26<08:41, 17.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 67%|██████▋   | 57/85 [16:45<08:26, 18.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 68%|██████▊   | 58/85 [17:02<08:02, 17.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|██████▉   | 59/85 [17:20<07:44, 17.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|███████   | 60/85 [17:38<07:27, 17.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 72%|███████▏  | 61/85 [17:56<07:08, 17.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 73%|███████▎  | 62/85 [18:13<06:46, 17.66s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|███████▍  | 63/85 [18:31<06:29, 17.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 75%|███████▌  | 64/85 [18:48<06:11, 17.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 76%|███████▋  | 65/85 [19:06<05:53, 17.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 78%|███████▊  | 66/85 [19:24<05:40, 17.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 79%|███████▉  | 67/85 [19:43<05:26, 18.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|████████  | 68/85 [20:01<05:08, 18.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 81%|████████  | 69/85 [20:19<04:50, 18.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 82%|████████▏ | 70/85 [20:37<04:31, 18.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 84%|████████▎ | 71/85 [20:55<04:10, 17.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 85%|████████▍ | 72/85 [21:13<03:52, 17.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|████████▌ | 73/85 [21:31<03:34, 17.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 87%|████████▋ | 74/85 [21:49<03:17, 18.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 88%|████████▊ | 75/85 [22:07<03:00, 18.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|████████▉ | 76/85 [22:25<02:41, 17.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|█████████ | 77/85 [22:42<02:23, 17.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 92%|█████████▏| 78/85 [23:01<02:05, 17.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 93%|█████████▎| 79/85 [23:18<01:47, 17.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████▍| 80/85 [23:36<01:29, 17.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 95%|█████████▌| 81/85 [23:53<01:10, 17.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 96%|█████████▋| 82/85 [24:11<00:52, 17.61s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 98%|█████████▊| 83/85 [24:29<00:35, 17.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 99%|█████████▉| 84/85 [24:47<00:17, 17.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████| 85/85 [25:03<00:00, 17.69s/it]\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "preds = []\n",
    "for row in tqdm(test.batch(20)): # type: ignore\n",
    "    text_input_ids = torch.LongTensor(row['input_ids']).to('cuda:0') # type: ignore\n",
    "    text_attention_mask = torch.LongTensor(row['attention_mask']).to('cuda:0') # type: ignore\n",
    "\n",
    "    model_out = model.generate(\n",
    "        input_ids=text_input_ids, \n",
    "        attention_mask=text_attention_mask,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        max_new_tokens=300,\n",
    "        top_k=1,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    labels_decoded = tokenizer.batch_decode(\n",
    "        row['labels'], # type: ignore\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    preds_decoded = tokenizer.batch_decode(\n",
    "        model_out,\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    for i in range(len(labels_decoded)):\n",
    "        if 'ответ:' in labels_decoded[i] and 'ответ:' in preds_decoded[i]:\n",
    "            preds.append(preds_decoded[i].split('ответ:')[1])\n",
    "            targets.append(labels_decoded[i].split('ответ:')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель не может показать на указанном датасете устойчивую сходимость, а так же имеет худшую оценку по метрикам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrice:\n",
      "Meteor: 0.014381068980355698\n",
      "Rouge: 0.0,\n",
      "Bleu: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Test metrice:\n",
    "Meteor: {meteor.compute(predictions=preds, references=targets)['meteor']}\n",
    "Rouge: {rouge.compute(predictions=preds, references=targets)['rougeLsum']},\n",
    "Bleu: {bleu.compute(predictions=preds, references=targets)['bleu']}\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
